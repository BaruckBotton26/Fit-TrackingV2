# ğŸ‹ï¸ Fit Tracking V2

**Fit Tracking V2** es una aplicaciÃ³n iOS de anÃ¡lisis de ejercicios basada en visiÃ³n por computadora, que permite detectar errores comunes en la postura durante rutinas fÃ­sicas mediante el anÃ¡lisis de video y la visualizaciÃ³n de puntos clave del cuerpo humano.

## ğŸš€ Â¿QuÃ© hace la app?

- Permite **grabar un video** desde la cÃ¡mara del dispositivo.
- **usa la cÃ¡mara en tiempo real**, mediante el sistema de **post-procesamiento de QuickPose**.
- Detecta errores comunes de postura como:
  - ğŸ”´ Profundidad insuficiente
  - ğŸ”´ Rodillas desalineadas
  - ğŸŸ¡ PÃ©rdida de tensiÃ³n en el core
- Muestra una vista de retroalimentaciÃ³n visual y textual luego del anÃ¡lisis.
- Usa arquitectura **MVVM** con separaciÃ³n entre vistas, servicios y lÃ³gica de procesamiento.

## ğŸ§  TecnologÃ­as utilizadas

- `SwiftUI`
- `AVFoundation`
- [`QuickPose iOS SDK`](https://quickpose.ai/products/ios-sdk/)
  - QuickPoseCore
  - QuickPoseCamera
- CocoaPods (para manejo de dependencias)

## ğŸ§© Funcionalidades implementadas

| Funcionalidad                  | Estado  |
|-------------------------------|---------|
| GrabaciÃ³n de video            | âœ…      |
| Post-procesamiento del video  | âœ…      |
| AnÃ¡lisis y retroalimentaciÃ³n  | âœ…      |
| NavegaciÃ³n entre vistas       | âœ…      |

## ğŸ“ˆ Avances semanales

- **Semana Anteriores:** IntegraciÃ³n completa con el SDK de QuickPose para post-procesamiento y visualizaciÃ³n de articulaciones.
- Se reemplazÃ³ MediaPipe por QuickPose para mejorar rendimiento y control en dispositivos iOS.
- Se logrÃ³ representar con Ã©xito los **33 puntos clave del cuerpo humano**, incluyendo pies y manos.
- Se automatizÃ³ la navegaciÃ³n a la vista de Feedback tras el procesamiento del video.
- ImplementaciÃ³n de lÃ³gica visual de retroalimentaciÃ³n (errores y recomendaciones).
- **Semana actual:** FinalizaciÃ³n automÃ¡tica de la evaluaciÃ³n mediante detecciÃ³n de quietud corporal prolongada.
- Se implementÃ³ lÃ³gica para detectar 5 segundos de reposo seguidos de 3 segundos sin movimiento para finalizar sin necesidad de presionar un botÃ³n.
- Se mantiene opciÃ³n de finalizaciÃ³n manual mediante botÃ³n visible durante la evaluaciÃ³n.
- EvaluaciÃ³n de repeticiones y errores posturales ahora ocurre solo tras detectar el gesto de pulgar arriba.
- Se optimizÃ³ la detecciÃ³n de errores como valgo, butt wink, asimetrÃ­a, y elevaciÃ³n de talÃ³n con lÃ³gica por porcentaje de frames y segundos acumulados.
- Se integrÃ³ guardado automÃ¡tico en Firebase de repeticiones, tiempos y errores tras finalizar la evaluaciÃ³n (manual o automÃ¡tica).



## ğŸ—‚ï¸ Estructura del proyecto

FitTrackingV2/
â”‚
â”œâ”€â”€ Services/ # QuickPoseService, manejo del procesamiento
â”œâ”€â”€ ViewModels/ # LÃ³gica de estado (Feedback, Inicio, QuickPose)
â”œâ”€â”€ Views/ # SwiftUI views (EvaluacionView, FeedbackView, etc.)
â”œâ”€â”€ Assets/ # Recursos visuales y configuraciones
â””â”€â”€ Pods/ # Dependencias gestionadas por CocoaPods


## ğŸ“‹ Requisitos

- iOS 14.0+
- Xcode 15+
- SDK Key de QuickPose (gratis en [https://dev.quickpose.ai](https://dev.quickpose.ai))

## ğŸ§ª PrÃ³ximos pasos

- AÃ±adir mÃ©tricas cuantitativas del desempeÃ±o (repeticiones, rango de movimiento)
- Implementar exportaciÃ³n o reporte de resultados.
- Mejorar el sistema de retroalimentaciÃ³n con IA mÃ¡s especializada por ejercicio.
- Posible soporte multiplataforma en versiones futuras.

---

ğŸ¯ *Este proyecto forma parte de una tesis orientada al anÃ¡lisis automatizado de movimientos fÃ­sicos y correcciÃ³n de posturas utilizando visiÃ³n por computadora y modelos de pose estimation.*
